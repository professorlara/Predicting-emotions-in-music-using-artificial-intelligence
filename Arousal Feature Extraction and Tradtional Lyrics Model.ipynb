{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1c91fec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\nTOP 20 features that have a high mutual info score w/ arousal:\\nINDEX 0 : adjective_count SCORE: 0.05082632896920991\\nINDEX 1 : num_words SCORE: 0.04876484449326757\\nINDEX 2 : num_5grams SCORE: 0.04837045280215513\\nINDEX 3 : num_4grams SCORE: 0.04821393048227751\\nINDEX 4 : num_unique_bigrams SCORE: 0.047744072700954376\\nINDEX 5 : num_unique_trigrams SCORE: 0.04765633572761274\\nINDEX 6 : num_unique_5grams SCORE: 0.04755501286334418\\nINDEX 7 : num_trigrams SCORE: 0.047505371216749026\\nINDEX 8 : number_lines SCORE: 0.04738084578128987\\nINDEX 9 : num_bigrams SCORE: 0.046992205977806734\\nINDEX 10 : non3rdpersonsingularpresent_verb_count SCORE: 0.04570499626396973\\nINDEX 11 : num_unique_4grams SCORE: 0.04524936674246405\\nINDEX 12 : noun_count SCORE: 0.042097992805620876\\nINDEX 13 : base_verb_count SCORE: 0.03753682045568851\\nINDEX 14 : TOTAL_verb_count SCORE: 0.03736745136731923\\nINDEX 15 : content_density SCORE: 0.03458158557082136\\nINDEX 16 : pastparticiple_verb_freq SCORE: 0.032048842533438204\\nINDEX 17 : personal_pronoun_count SCORE: 0.03104155923545271\\nINDEX 18 : 3rdpersonsingularpresent_verb_count SCORE: 0.02365818734652958\\nINDEX 19 : coordinating_conjunctions_freq SCORE: 0.020881204698388167\\nINDEX 20 : preposition_count SCORE: 0.020388547792320466\\n\\n\\nFeatures we want to compute:\\n-word count\\n-number of lines\\n-content density (type-token ratio)\\n\\n-number of unique bigrams\\n-number of 4-grams\\n-number of 5-grams\\n-number of unique 5-grams\\n\\n-adjective_count\\n-noun_count\\n-base_verb_count\\n-TOTAL_verb_count\\n-preposition_count\\n-personal_pronoun_count\\n\\n-non3rdpersonsingularpresent_verb_count\\n-3rdpersonsingularpresent_verb_count\\n\\n-coordinating_conjunctions_freq\\n-pastparticiple_verb_freq\\n\\n\\n\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''\n",
    "TOP 20 features that have a high mutual info score w/ arousal:\n",
    "INDEX 0 : adjective_count SCORE: 0.05082632896920991\n",
    "INDEX 1 : num_words SCORE: 0.04876484449326757\n",
    "INDEX 2 : num_5grams SCORE: 0.04837045280215513\n",
    "INDEX 3 : num_4grams SCORE: 0.04821393048227751\n",
    "INDEX 4 : num_unique_bigrams SCORE: 0.047744072700954376\n",
    "INDEX 5 : num_unique_trigrams SCORE: 0.04765633572761274\n",
    "INDEX 6 : num_unique_5grams SCORE: 0.04755501286334418\n",
    "INDEX 7 : num_trigrams SCORE: 0.047505371216749026\n",
    "INDEX 8 : number_lines SCORE: 0.04738084578128987\n",
    "INDEX 9 : num_bigrams SCORE: 0.046992205977806734\n",
    "INDEX 10 : non3rdpersonsingularpresent_verb_count SCORE: 0.04570499626396973\n",
    "INDEX 11 : num_unique_4grams SCORE: 0.04524936674246405\n",
    "INDEX 12 : noun_count SCORE: 0.042097992805620876\n",
    "INDEX 13 : base_verb_count SCORE: 0.03753682045568851\n",
    "INDEX 14 : TOTAL_verb_count SCORE: 0.03736745136731923\n",
    "INDEX 15 : content_density SCORE: 0.03458158557082136\n",
    "INDEX 16 : pastparticiple_verb_freq SCORE: 0.032048842533438204\n",
    "INDEX 17 : personal_pronoun_count SCORE: 0.03104155923545271\n",
    "INDEX 18 : 3rdpersonsingularpresent_verb_count SCORE: 0.02365818734652958\n",
    "INDEX 19 : coordinating_conjunctions_freq SCORE: 0.020881204698388167\n",
    "INDEX 20 : preposition_count SCORE: 0.020388547792320466\n",
    "\n",
    "\n",
    "Features we want to compute:\n",
    "-word count\n",
    "-number of lines\n",
    "-content density (type-token ratio)\n",
    "\n",
    "-number of unique bigrams\n",
    "-number of 4-grams\n",
    "-number of 5-grams\n",
    "-number of unique 5-grams\n",
    "\n",
    "-adjective_count\n",
    "-noun_count\n",
    "-base_verb_count\n",
    "-TOTAL_verb_count\n",
    "-preposition_count\n",
    "-personal_pronoun_count\n",
    "\n",
    "-non3rdpersonsingularpresent_verb_count\n",
    "-3rdpersonsingularpresent_verb_count\n",
    "\n",
    "-coordinating_conjunctions_freq\n",
    "-pastparticiple_verb_freq\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "206f6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\larae\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\larae\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\larae\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\larae\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\larae\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae6e430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\larae\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "03441ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygal\n",
      "  Obtaining dependency information for pygal from https://files.pythonhosted.org/packages/29/83/94e10cdc24489caef1ffcf9c3c2836fc35eff0f1c1d60d609d55d449820c/pygal-3.0.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading pygal-3.0.4-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\larae\\anaconda3\\lib\\site-packages (from pygal) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\larae\\anaconda3\\lib\\site-packages (from importlib-metadata->pygal) (3.11.0)\n",
      "Downloading pygal-3.0.4-py2.py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.4 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/130.4 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 30.7/130.4 kB 445.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 122.9/130.4 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 130.4/130.4 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pygal\n",
      "Successfully installed pygal-3.0.4\n"
     ]
    }
   ],
   "source": [
    "! pip install pygal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "dac9ba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\larae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "94790ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c76bb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions\n",
    "def wordcount(text):\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "def lines(text):\n",
    "    res = \"\"\n",
    "    for i in text:\n",
    "        if(i.isupper()):\n",
    "            res+=\"*\"+i\n",
    "        else:\n",
    "            res+=i\n",
    "    m=res.split(\"*\")\n",
    "    m.remove('')\n",
    "    numlines = len(m)\n",
    "    return numlines\n",
    "\n",
    "def type_token_ratio(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    ttr = len(unique_words) / len(words) if words else 0\n",
    "    return ttr\n",
    "\n",
    "def ngrams(text, n):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n))\n",
    "    analyzer = vectorizer.build_analyzer()\n",
    "    n_grams = analyzer(text)\n",
    "    return len(n_grams)\n",
    "\n",
    "def unique_ngrams(text, n):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n))\n",
    "    analyzer = vectorizer.build_analyzer()\n",
    "    n_grams = analyzer(text)\n",
    "    return len(set(n_grams))\n",
    "\n",
    "def wordclass(text, category):\n",
    "    blob = TextBlob(text)\n",
    "    tags = blob.tags\n",
    "    \n",
    "    counts = {\n",
    "        'adjective': 0,\n",
    "        'noun': 0,\n",
    "        'base_verb': 0,\n",
    "        'total_verb': 0,\n",
    "        'preposition': 0,\n",
    "        'personal_pronoun': 0,\n",
    "        'non3rdpersonsingularpresent_verb': 0,\n",
    "        '3rdpersonsingularpresent_verb': 0,\n",
    "        'past_participle_verb': 0,\n",
    "        'coordinating_conjunctions': 0\n",
    "    }\n",
    "    \n",
    "    for word, tag in tags:\n",
    "        if tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            counts['noun'] += 1\n",
    "        elif tag == 'IN':\n",
    "            counts['preposition'] += 1\n",
    "        elif tag == 'VB':\n",
    "            counts['base_verb'] += 1\n",
    "            counts['total_verb'] += 1\n",
    "        elif tag in ['VBD', 'VBG']:\n",
    "            counts['total_verb'] += 1\n",
    "        elif tag == 'VBN':\n",
    "            counts['total_verb'] += 1\n",
    "            counts['past_participle_verb'] += 1\n",
    "        elif tag == 'VBP':\n",
    "            counts['non3rdpersonsingularpresent_verb'] += 1\n",
    "            counts['total_verb'] += 1\n",
    "        elif tag == 'VBZ':\n",
    "            counts['3rdpersonsingularpresent_verb'] += 1\n",
    "            counts['total_verb'] += 1\n",
    "        elif tag in ['JJ', 'JJR', 'JJS']:\n",
    "            counts['adjective'] += 1\n",
    "        elif tag == 'CC':\n",
    "            counts['coordinating_conjunctions'] += 1\n",
    "        elif tag == 'PRP':\n",
    "            counts['personal_pronoun'] += 1\n",
    "    \n",
    "    content_density = (counts['total_verb'] + counts['noun'] + counts['adjective']) / wordcount(text)\n",
    "    past_participle_verb_freq = counts['past_participle_verb'] / wordcount(text)\n",
    "    coordinating_conjunctions_freq = counts['coordinating_conjunctions'] / wordcount(text)\n",
    "    \n",
    "    counts['content_density'] = content_density\n",
    "    counts['past_participle_verb_freq'] = past_participle_verb_freq\n",
    "    counts['coordinating_conjunctions_freq'] = coordinating_conjunctions_freq\n",
    "    \n",
    "    return counts[category]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6116a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please copy-paste the lyrics to your favourite song!Look at you, look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you,look at you.And I always find, yeah, I always find somethin' wrong You been puttin' up with' my shit just way too long I'm so gifted at findin' what I don't like the most So I think it's time for us to have a toast  Let's have a toast for the douchebags, Let's have a toast for the assholes, Let's have a toast for the scumbags, Every one of them that I know Let's have a toast to the jerkoffs That'll never take work off Baby, I got a plan Run away fast as you can  She find pictures in my email I sent this girl a picture of my dick. I don't know what it is with females But I'm not too good with that shit. See, I could have me a good girl And still be addicted to them hoodrats And I just blame everything on you At least you know that's what I'm good at  See, I always find And I always find Yeah, I always find somethin' wrong You been puttin' up with my shit just way too long I'm so gifted at findin' what I don't like the most So I think it's time for us to have a toast  Let's have a toast for the douchebags, Let's have a toast for the assholes, Let's have a toast for the scumbags, Every one of them that I know Let's have a toast to the jerkoffs That'll never take work off Baby, I got a plan Run away fast as you can  R-r-ru-ru-ru-run away Run away from me, baby  (Look at, look at, look at, look at you) Run away from me, baby (Look at you, look at you, look at you) Run away Run away from me, baby  24/7, 365, pussy stays on my mind I-I-I-I did it, all right, all right, I admit it Now pick your next move, you could leave or live with' it Ichabod Crane with that motherfuckin' top off Split and go where? Back to wearin' knockoffs, huh? Knock it off, Neiman's, shop it off Let's talk over mai tais, waitress, top it off Fools like vultures wanna fly in your Freddy loafers You can't blame 'em, they ain't never seen Versace sofas Every bag, every blouse, every bracelet Comes with a price tag, baby, face it You should leave if you can't accept the basics Plenty hoes in a baller-nigga matrix Invisibly set, the Rolex is faceless I'm just young, rich, and tasteless P!  Never was much of a romantic, I could never take the intimacy. And I know I did damage, 'Cause the look in your eyes is killing me, I guess you've got another advantage 'Cause you could blame me for everything. And I don't know how I'm a manage, If one day you just up and leave Yeah, I always find somethin' wrong You been puttin' up with my shit just way too long I'm so gifted at findin' what I don't like the most So I think it's time for us to have a toast  Let's have a toast for the douchebags, Let's have a toast for the assholes, Let's have a toast for the scumbags, Every one of them that I know Let's have a toast to the jerkoffs That'll never take work off Baby, I got a plan Run away fast as you can\n"
     ]
    }
   ],
   "source": [
    "# Input lyrics\n",
    "lyrics = input(\"Please copy-paste the lyrics to your favourite song!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8e6b3512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_words  number_lines  content_density  num_5grams  num_unique_5grams  \\\n",
      "0        592           113         0.342905         550                340   \n",
      "\n",
      "   num_4grams  num_unique_4grams  num_trigrams  num_unique_trigrams  \\\n",
      "0         551                331           552                  321   \n",
      "\n",
      "   num_bigrams  ...  adjective_count  noun_count  base_verb_count  \\\n",
      "0          553  ...               23         129               62   \n",
      "\n",
      "   preposition_count  personal_pronoun_count  \\\n",
      "0                 76                      96   \n",
      "\n",
      "   non3rdpersonsingularpresent_verb_count  \\\n",
      "0                                      34   \n",
      "\n",
      "   thirdpersonsingularpresent_verb_count  TOTAL_verb_count  \\\n",
      "0                                      9               126   \n",
      "\n",
      "   past_participle_verb_freq  coordinating_conjunctions_freq  \n",
      "0                   0.015203                        0.016892  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate required values\n",
    "num_words = wordcount(lyrics)\n",
    "number_lines = lines(lyrics)\n",
    "content_density = type_token_ratio(lyrics)\n",
    "num_5grams = ngrams(lyrics, 5)\n",
    "num_unique_5grams = unique_ngrams(lyrics, 5)\n",
    "num_4grams = ngrams(lyrics, 4)\n",
    "num_unique_4grams = unique_ngrams(lyrics, 4)\n",
    "num_trigrams = ngrams(lyrics, 3)\n",
    "num_unique_trigrams = unique_ngrams(lyrics, 3)\n",
    "num_bigrams = ngrams(lyrics, 2)\n",
    "num_unique_bigrams = unique_ngrams(lyrics, 2)\n",
    "\n",
    "adjective_count = wordclass(lyrics, 'adjective')\n",
    "noun_count = wordclass(lyrics, 'noun')\n",
    "base_verb_count = wordclass(lyrics, 'base_verb')\n",
    "preposition_count = wordclass(lyrics, 'preposition')\n",
    "personal_pronoun_count = wordclass(lyrics, 'personal_pronoun')\n",
    "non3rdpersonsingularpresent_verb_count = wordclass(lyrics, 'non3rdpersonsingularpresent_verb')\n",
    "thirdpersonsingularpresent_verb_count = wordclass(lyrics, '3rdpersonsingularpresent_verb')\n",
    "TOTAL_verb_count = wordclass(lyrics, 'total_verb')\n",
    "past_participle_verb_freq = wordclass(lyrics, 'past_participle_verb_freq')\n",
    "coordinating_conjunctions_freq = wordclass(lyrics, 'coordinating_conjunctions_freq')\n",
    "\n",
    "# Initialize dictionary\n",
    "result_dict = {\n",
    "    \"num_words\": num_words,\n",
    "    \"number_lines\": number_lines,\n",
    "    \"content_density\": content_density,\n",
    "    \"num_5grams\": num_5grams,\n",
    "    \"num_unique_5grams\": num_unique_5grams,\n",
    "    \"num_4grams\": num_4grams,\n",
    "    \"num_unique_4grams\": num_unique_4grams,\n",
    "    \"num_trigrams\": num_trigrams,\n",
    "    \"num_unique_trigrams\": num_unique_trigrams,\n",
    "    \"num_bigrams\": num_bigrams,\n",
    "    \"num_unique_bigrams\": num_unique_bigrams,\n",
    "    \"adjective_count\": adjective_count,\n",
    "    \"noun_count\": noun_count,\n",
    "    \"base_verb_count\": base_verb_count,\n",
    "    \"preposition_count\": preposition_count,\n",
    "    \"personal_pronoun_count\": personal_pronoun_count,\n",
    "    \"non3rdpersonsingularpresent_verb_count\": non3rdpersonsingularpresent_verb_count,\n",
    "    \"thirdpersonsingularpresent_verb_count\": thirdpersonsingularpresent_verb_count,\n",
    "    \"TOTAL_verb_count\": TOTAL_verb_count,\n",
    "    \"past_participle_verb_freq\": past_participle_verb_freq,\n",
    "    \"coordinating_conjunctions_freq\": coordinating_conjunctions_freq\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame([result_dict])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "58427dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>number_lines</th>\n",
       "      <th>content_density</th>\n",
       "      <th>num_5grams</th>\n",
       "      <th>num_unique_5grams</th>\n",
       "      <th>num_4grams</th>\n",
       "      <th>num_unique_4grams</th>\n",
       "      <th>num_trigrams</th>\n",
       "      <th>num_unique_trigrams</th>\n",
       "      <th>num_bigrams</th>\n",
       "      <th>...</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>base_verb_count</th>\n",
       "      <th>preposition_count</th>\n",
       "      <th>personal_pronoun_count</th>\n",
       "      <th>non3rdpersonsingularpresent_verb_count</th>\n",
       "      <th>thirdpersonsingularpresent_verb_count</th>\n",
       "      <th>TOTAL_verb_count</th>\n",
       "      <th>past_participle_verb_freq</th>\n",
       "      <th>coordinating_conjunctions_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592</td>\n",
       "      <td>113</td>\n",
       "      <td>0.342905</td>\n",
       "      <td>550</td>\n",
       "      <td>340</td>\n",
       "      <td>551</td>\n",
       "      <td>331</td>\n",
       "      <td>552</td>\n",
       "      <td>321</td>\n",
       "      <td>553</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>129</td>\n",
       "      <td>62</td>\n",
       "      <td>76</td>\n",
       "      <td>96</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>126</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.016892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_words  number_lines  content_density  num_5grams  num_unique_5grams  \\\n",
       "0        592           113         0.342905         550                340   \n",
       "\n",
       "   num_4grams  num_unique_4grams  num_trigrams  num_unique_trigrams  \\\n",
       "0         551                331           552                  321   \n",
       "\n",
       "   num_bigrams  ...  adjective_count  noun_count  base_verb_count  \\\n",
       "0          553  ...               23         129               62   \n",
       "\n",
       "   preposition_count  personal_pronoun_count  \\\n",
       "0                 76                      96   \n",
       "\n",
       "   non3rdpersonsingularpresent_verb_count  \\\n",
       "0                                      34   \n",
       "\n",
       "   thirdpersonsingularpresent_verb_count  TOTAL_verb_count  \\\n",
       "0                                      9               126   \n",
       "\n",
       "   past_participle_verb_freq  coordinating_conjunctions_freq  \n",
       "0                   0.015203                        0.016892  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "92b59e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBest modeltype/hyperparameters for predicting arousal\\nw/ traditional language model\\n\\nEstimator: GradientBoostingRegressor\\nMean absolute error: 0.8101\\nHyperparameters: \\ncriterion - squared error\\nlearning rate - 0.1\\nloss - absolute_error\\nminimum samples per leaf - 10\\nnumber of estimators - 200\\n'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Best modeltype/hyperparameters for predicting arousal\n",
    "w/ traditional language model\n",
    "\n",
    "Estimator: GradientBoostingRegressor\n",
    "Mean absolute error: 0.8101\n",
    "Hyperparameters: \n",
    "criterion - squared error\n",
    "learning rate - 0.1\n",
    "loss - absolute_error\n",
    "minimum samples per leaf - 10\n",
    "number of estimators - 200\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "08c87e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the training and validation data\n",
    "train = pd.read_csv('TRAIN language data.csv', delimiter=';')\n",
    "validate = pd.read_csv('VAL language data.csv', delimiter=';')\n",
    "\n",
    "# Combine the train and validate data\n",
    "train_validate = pd.concat([train, validate], ignore_index=True, sort=False)\n",
    "\n",
    "# Define the relevant features\n",
    "features = [\n",
    "    'adjective_count', 'num_words', 'num_5grams', 'num_4grams',\n",
    "    'num_unique_bigrams', 'num_unique_trigrams', 'num_unique_5grams',\n",
    "    'num_trigrams', 'number_lines', 'num_bigrams',\n",
    "    'non3rdpersonsingularpresent_verb_count', 'num_unique_4grams',\n",
    "    'noun_count', 'base_verb_count', 'TOTAL_verb_count', 'content_density',\n",
    "    'personal_pronoun_count','coordinating_conjunctions_freq',\n",
    "    'preposition_count'\n",
    "]\n",
    "\n",
    "# Extract the relevant features and target variable\n",
    "X = train_validate[features].applymap(lambda x: str(x).replace(',', '.')).astype(float)\n",
    "y = train_validate['arousal_tags'].apply(lambda x: str(x).replace(',', '.')).astype(float)\n",
    "\n",
    "# Replace inf, -inf, and NaN with 0\n",
    "X = X.replace((np.inf, -np.inf, np.nan), 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the GradientBoostingRegressor model\n",
    "model = GradientBoostingRegressor(\n",
    "    criterion='squared_error',\n",
    "    learning_rate=0.1,\n",
    "    loss='absolute_error',\n",
    "    min_samples_leaf=10,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3194fda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.8146712074555084\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Function to predict arousal on new data\n",
    "def predict_arousal(new_data):\n",
    "    new_data = new_data[features].applymap(lambda x: str(x).replace(',', '.')).astype(float)\n",
    "    new_data = new_data.replace((np.inf, -np.inf, np.nan), 0)\n",
    "    prediction = model.predict(new_data)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c7a7c193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on new data: [5.30794265]\n"
     ]
    }
   ],
   "source": [
    "#df = df[top_18_features].replace((np.inf, -np.inf, np.nan), 0)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_predictions = predict_arousal(df)\n",
    "print(\"Predictions on new data:\", new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1f78637f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRanges from 1-7, but a high percentage of values are between 3.5 - 5.5\\n\\nLow arousal: calm/relaxing <- 4\\n\\nModerate arousal: upbeat/rhythmic 4-5\\n\\nHigh Arousal: exciting/energetic 5 ->\\n\\n'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ranges from 1-7, but a high percentage of values are between 3.5 - 5.5\n",
    "\n",
    "Low arousal: calm/relaxing <- 4\n",
    "\n",
    "Moderate arousal: upbeat/rhythmic 4-5\n",
    "\n",
    "High Arousal: exciting/energetic 5 ->\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "42ec7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d7a22f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This song has a high arousal rating of 75.8 %.\n",
      "This rating suggests that it is exciting and energetic.\n"
     ]
    }
   ],
   "source": [
    "percentage =  round((new_predictions[0]/7)*100,1)\n",
    "\n",
    "\n",
    "if new_predictions < 4:\n",
    "    print(\"This song has a low arousal rating of\",str(percentage), \"%.\")\n",
    "    print(\"This rating suggests that it is calm and relaxing.\")\n",
    "    colour = 'lightblue'\n",
    "elif new_predictions >= 4 and new_predictions <=5:\n",
    "    print(\"This song has a moderate arousal rating of\", str(percentage), \"%.\")\n",
    "    print(\"This rating suggests that it is upbeat and rhythimical.\")\n",
    "    colour = 'lightgreen'\n",
    "else:\n",
    "    print(\"This song has a high arousal rating of\", str(percentage), \"%.\")\n",
    "    print(\"This rating suggests that it is exciting and energetic.\")\n",
    "    colour = 'orange'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7446c253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "arousal_rating = percentage\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "\n",
    "\n",
    "sections = ['Low', 'Moderate', 'High']\n",
    "colors = ['lightblue', 'lightgreen', 'orange']\n",
    "positions = [0, 33.33, 66.66, 100]  #\n",
    "\n",
    "\n",
    "for i in range(len(sections)):\n",
    "    ax.barh(0, positions[i + 1] - positions[i], left=positions[i], color=colors[i], edgecolor='white', height=1.0)\n",
    "\n",
    "#Needle\n",
    "needle_position = arousal_rating\n",
    "ax.plot([needle_position, needle_position], [-0.5, 0.5], color='black', linewidth=2)\n",
    "ax.text(needle_position, 0.65, f'{arousal_rating}%', horizontalalignment='center', verticalalignment='center', color='black', fontsize=12)\n",
    "\n",
    "#Labels\n",
    "label_positions = [(positions[i] + positions[i + 1]) / 2 for i in range(len(sections))]\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_xticks(label_positions)\n",
    "ax.set_xticklabels(sections)\n",
    "\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.title('Arousal Rating',y=-0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ba428ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file://C:/Users/larae/AppData/Local/Temp/tmp98hbmbrq.html\n"
     ]
    }
   ],
   "source": [
    "import pygal\n",
    "from pygal.style import Style\n",
    "\n",
    "\n",
    "custom_style = Style(\n",
    "        value_font_size=50,\n",
    "        value_colors=('black'),  \n",
    "        label_font_size=0,  \n",
    ")\n",
    "\n",
    "gauge = pygal.SolidGauge(\n",
    "        half_pie=True,\n",
    "        inner_radius=0.70,\n",
    "        show_legend=False,\n",
    "        style=custom_style\n",
    ")\n",
    "gauge.add('', [{'value': percentage, 'max_value': 100, 'color': colour}])\n",
    "gauge.render_in_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b14a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ecd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f23f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cac170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5be512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd40e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
